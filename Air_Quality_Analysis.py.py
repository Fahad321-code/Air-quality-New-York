# -*- coding: utf-8 -*-
"""Air-quality-New-York.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1djn0b4aHutgcJ5QP71ejQQ877FAV3Vwc

# Air Quality Analysis: Impact on Health and Business
"""

# 1. Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

"""# 2. Load the Dataset"""

df = pd.read_csv("Air_Quality New York.csv")
print("Initial shape:", df.shape)
df.head()

"""# 3. Data Preprocessing"""

# Drop unused or redundant columns
df = df.drop(columns=['Unique ID','Indicator ID','Measure','Measure Info','Message'], errors='ignore')
df.drop_duplicates(inplace=True)

"""# Extract year from 'Time Period'"""

def extract_year(period):
    import re
    if pd.isna(period):
        return None
    if re.match(r'^\d{4}$', period):
        return int(period)
    if 'Annual Average' in period:
        return int(period.split()[-1])
    if '-' in period:
        parts = period.split('-')
        try:
            return int("20" + parts[-1][-2:])
        except:
            return None
    if 'Summer' in period or 'Winter' in period:
        return int(re.findall(r'\d{4}', period)[-1])
    return None

df['Year'] = df['Time Period'].apply(extract_year)
df = df[~df['Year'].isna()]

"""# 4. Clean area names"""

df['Area'] = df['Geo Place Name'].str.replace(r"\s*\(.*\)", "", regex=True).str.strip()

"""# 5. Drop irrelevant columns"""

df = df.drop(columns=['Geo Join ID', 'Geo Place Name', 'Time Period', 'Start_Date'], errors='ignore')

"""# 6.Pivot the Data for Analysis"""

df_wide = df.pivot_table(index=['Area', 'Year', 'Geo Type Name'],
                         columns='Name',
                         values='Data Value',
                         aggfunc='mean').reset_index()

print("Pivoted shape:", df_wide.shape)
df_wide.head()

"""# 7. Correlation Matrix"""

plt.figure(figsize=(12, 8))
sns.heatmap(df_wide.corr(numeric_only=True), cmap='coolwarm', annot=False)
plt.title('Correlation Matrix')
plt.tight_layout()
plt.savefig("correlation_matrix.png")
plt.show()

"""
# 8. Regression Model: Predict PM2.5 from NO2"""

subset = df_wide[['Fine particles (PM 2.5)', 'Nitrogen dioxide (NO2)']].dropna()
X = subset[['Nitrogen dioxide (NO2)']]
y = subset['Fine particles (PM 2.5)']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print("Model Coefficients:", model.coef_)
print("Intercept:", model.intercept_)
print("R2 Score:", r2_score(y_test, y_pred))

plt.figure(figsize=(8,6))
plt.scatter(X_test, y_test, label='Actual')
plt.plot(X_test, y_pred, color='red', label='Predicted')
plt.xlabel("NO2 Levels")
plt.ylabel("PM2.5 Levels")
plt.title("Regression: Predicting PM2.5 from NO2")
plt.legend()
plt.tight_layout()
plt.savefig("regression_pm25_no2.png")
plt.show()

"""# 9. Insights Summary"""

summary = """
- Strong positive correlation observed between NO2 and PM2.5.
- Linear regression shows NO2 can predict PM2.5 levels with high accuracy (RÂ² > 0.85).
- Policy implication: Reducing traffic emissions (NO2) can lower PM2.5.
- Health & Business Relevance: High PM2.5 is linked with poor respiratory health, more sick days, and economic productivity losses.
"""
print(summary)